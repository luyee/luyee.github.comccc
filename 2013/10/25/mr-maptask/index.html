<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>MapReduce过程中的MapTask分析 | DonganWangshi</title>
  <meta name="author" content="DonganWangshi">
  
  <meta name="description" content="我们知道在Child中最终是通过调用taskFinal.run(job, umbilical); 来执行task的，这里task也是两种，这里先说说MapTask依据从JobTracker获取的Action，可以有cleanupJob,cleantask,setupjob,setuptask,以及M">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="MapReduce过程中的MapTask分析"/>
  <meta property="og:site_name" content="DonganWangshi"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="DonganWangshi" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">DonganWangshi</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-10-25T12:22:14.000Z"><a href="/2013/10/25/mr-maptask/">10月 25 2013</a></time>
      
      
  
    <h1 class="title">MapReduce过程中的MapTask分析</h1>
  

    </header>
    <div class="entry">
      
        <p>我们知道在Child中最终是通过调用taskFinal.run(job, umbilical); 来执行task的，这里task也是两种，这里先说说MapTask<br>依据从JobTracker获取的Action，可以有cleanupJob,cleantask,setupjob,setuptask,以及Map,当然在Reduce阶段还有reduce<br>Map分新，旧API，这里体现为runNewMapper与runOldMapper</p>
<figure class="highlight lang-java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre></td><td class="code"><pre>  <span class="annotation">@Override</span>
  <span class="keyword">public</span> <span class="keyword">void</span> run(<span class="keyword">final</span> JobConf job, <span class="keyword">final</span> TaskUmbilicalProtocol umbilical) 
    <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException {
    <span class="keyword">this</span>.umbilical = umbilical;

    <span class="comment">//与TaskTracker通信</span>
    <span class="comment">// start thread that will handle communication with parent</span>
    TaskReporter reporter = <span class="keyword">new</span> TaskReporter(getProgress(), umbilical,
        jvmContext);
    reporter.startCommunicationThread();
    <span class="keyword">boolean</span> useNewApi = job.getUseNewMapper();
    initialize(job, getJobID(), reporter, useNewApi);

    <span class="comment">// check if it is a cleanupJobTask</span>
    <span class="keyword">if</span> (jobCleanup) {
      runJobCleanupTask(umbilical, reporter);
      <span class="keyword">return</span>;
    }
    <span class="keyword">if</span> (jobSetup) {
      runJobSetupTask(umbilical, reporter);
      <span class="keyword">return</span>;
    }
    <span class="keyword">if</span> (taskCleanup) {
      runTaskCleanupTask(umbilical, reporter);
      <span class="keyword">return</span>;
    }

    <span class="keyword">if</span> (useNewApi) {
      runNewMapper(job, splitMetaInfo, umbilical, reporter);
    } <span class="keyword">else</span> {
      runOldMapper(job, splitMetaInfo, umbilical, reporter);
    }
    done(umbilical, reporter);
  }
</pre></td></tr></table></figure>

<p>先来看看新api吧：mapper.run(mapperContext);</p>
<figure class="highlight lang-java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
</pre></td><td class="code"><pre><span class="annotation">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)
  <span class="keyword">private</span> &lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;
  <span class="keyword">void</span> runNewMapper(<span class="keyword">final</span> JobConf job,
                    <span class="keyword">final</span> TaskSplitIndex splitIndex,
                    <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,
                    TaskReporter reporter
                    ) <span class="keyword">throws</span> IOException, ClassNotFoundException,
                             InterruptedException {
    <span class="comment">// make a task context so we can get the classes</span>
    org.apache.hadoop.mapreduce.TaskAttemptContext taskContext =
      <span class="keyword">new</span> org.apache.hadoop.mapreduce.TaskAttemptContext(job, getTaskID());
    <span class="comment">// make a mapper</span>
    org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; mapper =
      (org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;)
        ReflectionUtils.newInstance(taskContext.getMapperClass(), job);
    <span class="comment">// make the input format</span>
    org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt; inputFormat =
      (org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt;)
        ReflectionUtils.newInstance(taskContext.getInputFormatClass(), job);
    <span class="comment">// rebuild the input split</span>
    org.apache.hadoop.mapreduce.InputSplit split = <span class="keyword">null</span>;
    split = getSplitDetails(<span class="keyword">new</span> Path(splitIndex.getSplitLocation()),
        splitIndex.getStartOffset());

    org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input =
      <span class="keyword">new</span> NewTrackingRecordReader&lt;INKEY,INVALUE&gt;
          (split, inputFormat, reporter, job, taskContext);

    job.setBoolean(<span class="string">"mapred.skip.on"</span>, isSkipping());
    org.apache.hadoop.mapreduce.RecordWriter output = <span class="keyword">null</span>;
    org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;.Context 
         mapperContext = <span class="keyword">null</span>;
    <span class="keyword">try</span> {
      Constructor&lt;org.apache.hadoop.mapreduce.Mapper.Context&gt; contextConstructor =
        org.apache.hadoop.mapreduce.Mapper.Context.class.getConstructor
        (<span class="keyword">new</span> Class[]{org.apache.hadoop.mapreduce.Mapper.class,
                     Configuration.class,
                     org.apache.hadoop.mapreduce.TaskAttemptID.class,
                     org.apache.hadoop.mapreduce.RecordReader.class,
                     org.apache.hadoop.mapreduce.RecordWriter.class,
                     org.apache.hadoop.mapreduce.OutputCommitter.class,
                     org.apache.hadoop.mapreduce.StatusReporter.class,
                     org.apache.hadoop.mapreduce.InputSplit.class});

      <span class="comment">// get an output object</span>
      <span class="keyword">if</span> (job.getNumReduceTasks() == <span class="number">0</span>) {
         output =
           <span class="keyword">new</span> NewDirectOutputCollector(taskContext, job, umbilical, reporter);
      } <span class="keyword">else</span> {
        output = <span class="keyword">new</span> NewOutputCollector(taskContext, job, umbilical, reporter);
      }

      mapperContext = contextConstructor.newInstance(mapper, job, getTaskID(),
                                                     input, output, committer,
                                                     reporter, split);

      input.initialize(split, mapperContext);
      mapper.run(mapperContext);
      input.close();
      output.close(mapperContext);
</pre></td></tr></table></figure>

<p>新版中用户自定义的Mapper是通过最终调用contex.write()方法<br>这个contex其实是：TaskInputOutputContext</p>
<figure class="highlight lang-java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre>  <span class="javadoc">/**
   * Generate an output key/value pair.
   */</span>
  <span class="keyword">public</span> <span class="keyword">void</span> write(KEYOUT key, VALUEOUT value
                    ) <span class="keyword">throws</span> IOException, InterruptedException {
    output.write(key, value);
  }
</pre></td></tr></table></figure>

<p>这个output是：NewOutputCollector<K,V> 是MapTask的内部类</p>
<figure class="highlight lang-java"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre></td><td class="code"><pre>  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">NewOutputCollector</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;
    <span class="keyword">extends</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">hadoop</span>.<span class="title">mapreduce</span>.<span class="title">RecordWriter</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; {</span>
    <span class="keyword">private</span> <span class="keyword">final</span> MapOutputCollector&lt;K,V&gt; collector;
    <span class="keyword">private</span> <span class="keyword">final</span> org.apache.hadoop.mapreduce.Partitioner&lt;K,V&gt; partitioner;
    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> partitions;

    <span class="annotation">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)
    NewOutputCollector(org.apache.hadoop.mapreduce.JobContext jobContext,
                       JobConf job,
                       TaskUmbilicalProtocol umbilical,
                       TaskReporter reporter
                       ) <span class="keyword">throws</span> IOException, ClassNotFoundException {
      collector = <span class="keyword">new</span> MapOutputBuffer&lt;K,V&gt;(umbilical, job, reporter);
      partitions = jobContext.getNumReduceTasks();
      <span class="keyword">if</span> (partitions &gt; <span class="number">0</span>) {
        partitioner = (org.apache.hadoop.mapreduce.Partitioner&lt;K,V&gt;)
          ReflectionUtils.newInstance(jobContext.getPartitionerClass(), job);
      } <span class="keyword">else</span> {
        partitioner = <span class="keyword">new</span> org.apache.hadoop.mapreduce.Partitioner&lt;K,V&gt;() {
          <span class="annotation">@Override</span>
          <span class="keyword">public</span> <span class="keyword">int</span> getPartition(K key, V value, <span class="keyword">int</span> numPartitions) {
            <span class="keyword">return</span> -<span class="number">1</span>;
          }
        };
      }
    }

    <span class="annotation">@Override</span>
    <span class="keyword">public</span> <span class="keyword">void</span> write(K key, V value) <span class="keyword">throws</span> IOException, InterruptedException {
      collector.collect(key, value,
                        partitioner.getPartition(key, value, partitions));
    }

    <span class="annotation">@Override</span>
    <span class="keyword">public</span> <span class="keyword">void</span> close(TaskAttemptContext context
                      ) <span class="keyword">throws</span> IOException,InterruptedException {
      <span class="keyword">try</span> {
        collector.flush();
      } <span class="keyword">catch</span> (ClassNotFoundException cnf) {
        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"can't find class "</span>, cnf);
      }
      collector.close();
    }
  }
</pre></td></tr></table></figure>

<p>其write方法：</p>
<figure class="highlight lang-java"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre> <span class="annotation">@Override</span>
    <span class="keyword">public</span> <span class="keyword">void</span> write(K key, V value) <span class="keyword">throws</span> IOException, InterruptedException {
      collector.collect(key, value,
                        partitioner.getPartition(key, value, partitions));
    }
</pre></td></tr></table></figure>

<p>最终还是有到了collector，老版的Api最终是调用的Collector. 好吧MapOutputBuffer要来了，spill，ring神马滴都在这里</p>

      
    </div>
    <footer>
      
        
        
        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  

  
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2013 DonganWangshi
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>